CLUSTERING

K-Means
> set.seed()
> km.varName = kmeans (dataFrame, 2, nstart = 20) - 2 is the number of clusters, nstart is the number of random assignments, higher it is, smaller becomes km.varName$tot.withinss (total within cluster sum of squares)
> km.varName$withinss - individual within cluster sum of squares

Hierarchical clustering (Euclidean)
> hc.complete = hclust(dist(dataFrame), method = "complete") - complete can be replaced with "single" or "average" to change the linkage
> plot(hc.complete, main = "Name of graph", xlab = "", sub = "", cex=.9) - plots the dendrogram
> cutree(hc.complete, 2) - determines the cluster labels for each observation associated with a given cut of the dendrogram, 2 is for two clusters
> xsc = scale(x) - scale scales the variables before hier. clus.
> plot(hclust(dist(xsc), method... - plots the scaled variables

Hierarchical clustering (correlation-based distance)
> dd = as.dist(1- cor(t(x))) - as.dist() converts an arbitrary square symmetric matrix into a form that the hclust() function recognizes as a distance matrix, this makes sense only with at least 3 features
> plot(hclust (dd, method = "complete"), main = "Name of graph", xlab="", sub ="")
