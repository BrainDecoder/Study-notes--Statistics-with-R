MSE
MSE = E[(theta_bar-theta)^2], where MSE is mean square error, E is expectation, theta_bar is estimator of the sample (calculated in simulation), theta is the parameter of the population
Bias = E(theta_bar)-theta, the bias of an estimator
MSE = Variance + Bias^2, where Variance is a measure of spread of the sampling distribution of the estimator about its expectation 

Using BOOTSTRAP to find MSE for an Exponential distribution sample:
- the simulation should be done with x.samp <- rexp(sample size, lam)
Applies to similar model random samplings.

ESTIMATION OF PARAMETERS
Var(P_bar) = Var(X)/n = p(1-p)/n, formula for Bernoulli, where P_bar is the estimator or relative frequency of the event in the sample, p is probability of success for population
? lambda_bar = E(X_bar), for Poisson, where lambda_bar is the expectation of a Poisson measurement, E(X_bar) is the sample average of Poisson observations
? , for Uniform, 
lambda_bar = 1/X_bar, for Exponential, where lambda_bar is the estimator of the rate, X_bar is the sample average
? miu = E(X_bar); sigma^2 = Var(S^2), for Normal, miu and sigma^2 are parameters of population, S^2 is the sample variance 


CONFIDENCE INTERVALS for mean/expectation (CI) (standard Normal distribution situation, big sample)
> CI of Confidence Level (CL) 95% = x_bar +/- qnorm(0.975)*S/sqrt(n), where x_bar is sample mean, s is sample standard deviation, n is sample size
> CL = mean ((x_bar>=LCL & (x_bar<=UCL)), where x_bar is expected value of sample average, LCL/UCL are lower and upper confidence levels generated in simulation using CI formula above

> 95% CL = qnorm (0.975) = 1.96
> 90% CL = qnorm(0.95) = 1.645

CONFIDENCE INTERVALS for probability/proportion (standard Normal distribution situation, big sample)
> CI = p_hat +/- qnorm(0.975)*sqrt(p_hat*(1-p_hat)/n), where p_hat is estimate probability, n is sample size 
> CL = mean ((p >= LCL) & (p <= UCL)), where p is probability, LCL/UCL are lower and upper confidence levels generated in simulation using CI formula above

T-DISTRIBUTION for expectation (expectation of a Normal measurement situation, small sample)
> T-DISTRIBUTION (or test statistic) ~ (x_bar-E(X))/(S/sqrt(n)), where x_bar is sample average, E(X) is the hypothesis average, S is sample sd
> P ( |T-DISTRIBUTION| <= qt(0.975, n-1)) = 0.95
> CI = X_bar +/- qt(0.975, n-1) * S / sqrt(n), where CL is 95%, S is sample sd distribution, X_bar is sample mean distribution, n is the specific subgroup sample size  
> CL = mean ((x_bar>=LCL & (x_bar<=UCL)), where x_bar is the expectation of the measurement, not the one created in simulation 

> tapply (seq. of values, factor with subcategories, name of a function) = applies the function to each subcategory using the values 
> qt(0.975, 20) > [1] 2.085963 = qt computes the percentiles of the t-distribution
> qt(0.975, 200) > [1] 1.971896
> qt(0.975, 2000) > [1] 1.961151

CHI-square for proportion (expectation of a Normal measurement situation, small sample)
> CHI-square ~ (n-1)*S^2/sig^2, where S is sample standard deviation, sig is population standard deviation
> P (qchisq(0.025, n-1) <= CHI-square <= qchisq(0.975, n-1)) = 0.95
> CI = [(n-1)*S^2/qchisq(0.975, n-1), (n-1)*S^2/qchisq(0.025, n-1)], n is the specific subgroup sample size, first is LCL
> qchisq (probability, nr. of degrees of freedom) = calculates the percentiles of the chi-square distribution associated with the probability 

SAMPLE SIZE calculation (for proportions)
n = (p(1-p)z^2)/m^2, where max value of p(1-p) is 0.25 when p = 0.5 (the safe approach), m is margin of error, z is z score corresponding to significance level
n = (qnorm(0.975)/0.02)^2, when radius is no more than 0.01 (0.01*2 in formula) for CI of 95%


HYPOTHESIS testing
E(X) - parameter of interest 
H0 : E(X) = 13662 - null hypothesis, when the phenomena (of difference between prices) is absent, E(X) = 13662
H1 : E(X) != 13662 - alternative hypothesis, when the phenomena is present, E(X) != 13662
H1:E(X)!=13662 = two sided alternative
H1:E(X)>13662 or H1:E(X)<13662 = one sided alternative 
Test statistic = (x_bar-E(X))/(S/sqrt(n)), where x_bar is sample average, E(X) is the hypothesis average, S is sample sd

Testing hypothesis on the expectation
{|T|>c} = rejection region for two sided, where c is the threshold usually equal to qt(0.975, n-1) which produces a test with a 5% significance level, T is statistic calculated as t-distribution 
{T>c} = rejection region for one sided alternative, where c is qt(0.95, n-1), 5% significance level
p-value = P(|T|>|t|), where t is the observed value of the T statistic (for 2-sided), or T-DISTRIBUTION, or test statistic 
p-value for 2-sided = 2*(1-pt(|t|, n-1)), where t is t-distribution
p-value for 1-sided = 1-pt(t, n-1), where t is t-distribution
t.test(cars$price, mu=13662) = mu is the expected value we want to test, for 2-sided alternative
t.test(cars$price, mu=13662, alternative="greater") = for one sided alternative

Testing hypothesis on proportion
H0 : p = 0.5, true when 0 is the center of the sampling distribution of the test statistic Z
H1 : p != 0.5
Z = (p_hat - p) / sqrt(p(1-p)/n)
{|Z| > c} = {Z^2 > c^2} = rejection region
prop.test(nr. or occurrences, n, p = 0.25) = produces statistical tests for proportions; CI for probability where n is sample size, nr. is failed examples, p is H0 probability of the event 

Calculating significance level
1. simulation based on specific model 
2. T <- (X.bar - 5)/(S/sqrt( n )), where T is the test statistic, the whole formula is determined by situation/task, X.bar is the sample mean calculated inside the simulation, S is the sd calculated inside the simulation, n is sample size
3. mean(T > qt(0.95, n-1)), where (>...) is the threshold that determines the rejection region 


Extracting categories from datasets
> w <- c(5,3,4,6,2,9)
> d <- c(13,22,0,12,6,20)
> w > 5
[1] FALSE FALSE FALSE TRUE FALSE TRUE
> d[w > 5] = extracts from d values on the same positions as in w that meet in w the w>5 condition
[1] 12 20

The Permutation Test
> x <- unpaired$extra
# t is test statistic
> t <- abs(mean(x[1:10])-mean(x[11:20]))
> T <- rep(0,10^5)
> for (i in 1:10^5) {
+     X <- sample(x)
+     T[i] <- abs(mean(X[1:10])-mean(X[11:20]))
+ }
# p-value is calculated using the P(|T|>|t|) formula
> mean (T > t) 


COMPARING 2 SAMPLES
In statistics, the Explanatory variable (like x in math) has effect on the distribution of values of second variable, called the Response (f(x) in math). 
> plot(dif.mpg~heavy) = plot(response~explanatory.variable) = creates 2 box plots, for TRUE and FALSE values from heavy, on the dif.mpg scale
> t.test(dif.mpg~heavy) = finds the significance difference between the 2 groups from Heavy in the expectation of the dif.mpg score

Comparing sample variances
> qf(0.025, dfa, dfb), where 0.025 is the percentile, dfa and dfb are degrees of freedom
> qf(c(0.05,0.95), dfa, dfb), calc. the region that contains 90% of the distribution of the statistic
> (s.a^2/s.b^2)/qf(0.975,n.a-1,n.b-1) = calculates the lower limit of the confidence interval with a 95% confidence level 
> var.test(dif.mpg~heavy) = finds the significance difference between the 2 groups from Heavy in the variance of the dif.mpg score

Formulas:
> t <- abs(x.bar.a-x.bar.b)/sqrt(s.a^2/n.a + s.b^2/n.b) = calculates the absolute value of the test statistic for 2 samples
> 2*(1-pnorm(t)) = calculates p-value, t is from formula above

Actual CL of the CI:
1. Simulation where for both sub-populations the sample sd is calculated 
2. F <- S.a^2/S.b^2 = the distribution of the ration of estimators of the variance 
3. mean((F/qf(0.025,n.a-1,n.b-1) >= 4)&(F/qf(0.975,n.a-1,n.b-1) <= 4)), where 4 is the actual value of the estimated parameter


LINEAR REGRESSION
> plot(y~x, data=file.name) = builds a scater plot with x and y axes, where y=f(x)
> abline (a, b, col="green") = adds to the plot a green line with a intercept and b slope (y=a+b*x)
> cov(x,y) = sum((y-mean(y))*(x-mean(x)))/(n-1) = computes the covariance
> b <- cov(x,y)/var(x) = computes the slope
> a <- mean(y) - b*mean(x) = computes the intercept 

* a+b*x = y, where y is the expected value on the regression line = the estimated expectation of the response
* residual = y - (a+b*x), where y is the observed response, x is the observed explanatory 

> abline(lm(y~x)) = draws the regression line on the plot 
> summary((y~x)) = computes in a table the estimated value, estimated sd, test statistic, and p-value for the intercept (row 1) and slope (row 2)
> confint (lm(y~x)) = computes CI for the intercept and slope based on t-distribution (for Normal aproximation see pag. 260 top)
> residuals(lm(y~x)) = calculates the residuals
> sqrt(sum(risiduals(lm(y~x))^2)/n-2) = the sd of the response from the regression model 

> 1-var(residuals(lm(y~x)))/var(y) = computes un-adjusted R-squared/Multiple R-squared = the part of the variance of response explained by the explanatory variable 
> 1-(sum(residuals(lm(y~x))^2)/n-2/var(y) = computes adjusted R-squared, becomes very close to un-adjusted for large nr or observations 


Bernoulli Response 
> plot(num.of.doors ~ fuel.type,data=cars) = creates a mosaic plot (response~explanatory)
> summary(glm(cars$num.of.doors=="four"~cars$length, family=binomial)) = tests the hypothesis for logic regression; tests the hypothesis that the indicator of type (the response, four in this case) and an explanatory variable are unrelated  
> confint(glm(...)) = computes the confidence intervals 
> confint(glm(..., subset=(type!="u"))) = excludes type u from the calculations
> prop.test(table(cars$fuel.type, cars$num.of.doors)) = calculates the proportions for 2 fuel.types (explanatory) vs. 2 doors type-cars (response); tests the null hypothesis that the probabilities of 2 subcategories are equal; calculates the CI for the difference in probabilities; the estimate of the subcategories probabilities.
